---
layout: default
title: Pretraining a Transformer from scratch with KerasNLP
nav_order: 2
permalink: /guides/keras_nlp/transformer_pretraining/
parent: KerasNLP
grand_parent: 개발자 가이드
---

* 원본 링크 : [https://keras.io/guides/keras_nlp/transformer_pretraining/](https://keras.io/guides/keras_nlp/transformer_pretraining/){:target="_blank"}
* 최종 수정일 : 2024-03-29

# Pretraining a Transformer from scratch with KerasNLP
{: .no_toc }

## 목차
{: .no_toc .text-delta }

1. TOC
{:toc}

---

**저자:** [Matthew Watson](https://github.com/mattdangerw/)  
**생성일:** 2022/04/18  
**최종편집일:** 2023/07/15  
**설명:** Use KerasNLP to train a Transformer model from scratch.

[Colab에서 보기](https://colab.research.google.com/github/keras-team/keras-io/blob/master/guides/ipynb/keras_nlp/transformer_pretraining.ipynb){: .btn .btn-blue }
[GitHub 소스](https://github.com/keras-team/keras-io/blob/master/guides/keras_nlp/transformer_pretraining.py){: .btn .btn-blue }

----